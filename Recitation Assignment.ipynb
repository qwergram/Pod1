{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Assignment (Objective)\n",
    "\n",
    "For this assignment, we are using a machine learning algorithm called KNN to determine what sorts of people were likely to survive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "The data provided are in files called `train.csv` and `test.csv`. \n",
    "\n",
    "`train.csv` contains a column named `survived` which states whether that individual survived or not. In `test.csv`, that column does not exist. We are using data we gathered from `train.csv` using the KNN algorithm to predict the `survived` status on each row (person) of the `test.csv`.\n",
    "\n",
    "We will be using this data to see what traits of people made it more likely for that individual to survive. We will be using `train.csv` to train our machine learning algorithm first. To initialize, we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy\n",
    "#from scipy.stats import mode\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import DistanceMetric \n",
    "from pprint import pprint\n",
    "\n",
    "TITANIC_TRAIN = 'train.csv'\n",
    "TITANIC_TEST  = 'test.csv'\n",
    "\n",
    "dataframe = pd.read_csv(TITANIC_TRAIN, header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The header parameter represents which line of the CSV is the header. We can then also call builtin functions that would normally work on dictionaries or lists with our new Dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length: 891 \n"
     ]
    }
   ],
   "source": [
    "print('length: {0} '.format(len(dataframe)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also call a `.info()` method on our data to take a glance at the number of entries under each column. This gives us an idea of what data is present, and what isn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the table contains data on 891 people. We can also see that every single column contains information on each person excluding `Cabin` and `Age`. SciPy cannot process rows with `None` values, so we must handle the data somehow. Since `Cabin` contains only 204 entries, we might as well consider it obsolete information, on the other hand, we are only missing 100 entries from the Age column, so we can use the column.\n",
    "\n",
    "We can't just call `dataframe.dropna()` because we want to keep the data, so we need to create a parser to insert mean data into the missing fields. To calculate the mean, we can check using some of the methods provided by Pandas.\n",
    "\n",
    "We've determined that the rows that may be relevent to passenger survival are:\n",
    "- Pclass\n",
    "- Sex\n",
    "- Age\n",
    "- SibSp\n",
    "- Parch\n",
    "- Embarked\n",
    "\n",
    "We will drop the columns that aren't likely to affect chances of survival:\n",
    "- PassgengerId\n",
    "- Name\n",
    "- Ticket\n",
    "\n",
    "We will drop the columns that don't provide enough information as well:\n",
    "- Cabin\n",
    "\n",
    "To drop, we call the following command.\n",
    "We set the axis to 1 because we want to delete the row and not the column\n",
    "The `inplace` determines whether we are replacing our current `Dataframe` with the dropped columns or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null object\n",
      "Age         714 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 55.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Syntatic Sugars\n",
    "COLUMNS = 0\n",
    "ROWS = 1\n",
    "\n",
    "# Defenestrate the columns we don't need\n",
    "dataframe.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=ROWS, inplace=True)\n",
    "print(dataframe.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we got of the useless columns. Now we need to find the mean of the age and supply it as the age for the missing rows.\n",
    "\n",
    "We can find the mean age using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.69911764705882\n"
     ]
    }
   ],
   "source": [
    "mean = dataframe.Age.mean()\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then set the rows with no Age entry to the mean using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe.Age.fillna(mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the table looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null object\n",
      "Age         891 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    889 non-null object\n",
      "dtypes: float64(2), int64(4), object(2)\n",
      "memory usage: 55.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we should take a look at is the `Embarked` Column, each entry in there is not an integer, which will cause SciPy problems down the road. We'll be using Python's `map` builtin to convert each `Embark` to a number. However we don't want to overwrite the current letters, so we'll assign this new integer based destination to a new key called `port`\n",
    "\n",
    "There are still `Embarked` values that are null, so we must assign them to `0`.\n",
    "\n",
    "(We set replace `Embarked` with `Port` because you did it that way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "# To see each destination we can call:\n",
    "print(dataframe['Embarked'].unique())\n",
    "# After we confirm that there are only C, S and Q, we can map it\n",
    "dataframe['Embarked'] = dataframe['Embarked'].map({'C':1, 'S':2, 'Q':3, None: 0}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data set is complete, however, we need to replace all non-int64/float64 object types with int64/float64 object types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null object\n",
      "Age         891 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    891 non-null int64\n",
      "dtypes: float64(2), int64(5), object(1)\n",
      "memory usage: 55.8+ KB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the `Sex` is currently listed as an `object` type. To fix that, we use Python's `map` builtin again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "# To see each destination we can call:\n",
    "print(dataframe['Sex'].unique())\n",
    "# After we confirm that there are only male and female, we can map it\n",
    "dataframe['Sex'] = dataframe['Sex'].map({'male':0, 'female':1}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that the type of `Sex` entries are `int64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      "Survived    891 non-null int64\n",
      "Pclass      891 non-null int64\n",
      "Sex         891 non-null int64\n",
      "Age         891 non-null float64\n",
      "SibSp       891 non-null int64\n",
      "Parch       891 non-null int64\n",
      "Fare        891 non-null float64\n",
      "Embarked    891 non-null int64\n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 55.8 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did it! We can now put our data into `SciKit`. We can now create a KNN Classifier Object that we can now train with our training cleaned `dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = neighbors.KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a Classifier Object using the KNN machine learning algorithm. Next thing we want to do is splice our columns. Essentially what the following lines of codes is splitting our table into two.\n",
    "\n",
    "Table train_columns:\n",
    "- Pclass\n",
    "- Sex\n",
    "- Age\n",
    "- SibSp\n",
    "- Parch\n",
    "- Fare\n",
    "- Embarked\n",
    "\n",
    "Table target_columns:\n",
    "- Survived\n",
    "\n",
    "The reason we do this is because we want to ask SciPy to look at every single row in our training data and find a pattern between all the data and train_columns and target_columns. In other words: Does your status in: `[Pclass, Sex, Age, SibSp, Parch, Fare, Embarked]` affect our chance of `Survived`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'] ['Survived']\n"
     ]
    }
   ],
   "source": [
    "# Convert our columns to lists\n",
    "columns = dataframe.columns.tolist()\n",
    "dataframe = dataframe[columns]\n",
    "\n",
    "# Extrapolate from those columns\n",
    "train_columns = columns[1:]\n",
    "target_columns = [columns[0]]\n",
    "print(train_columns, target_columns)\n",
    "\n",
    "# Get the data from those columns\n",
    "train_data = dataframe[train_columns]\n",
    "target_data = dataframe[target_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_columns` represents a list containing the columns as you can see in the last print statement.\n",
    "`_data` actually contains the data associated with those columns.\n",
    "\n",
    "Next, we need to feed our KNClasifier object our training data. For the first parameter you pass in `train_data.values` which returns a Two-dimensional array containing everything in your table except for the columns `Survived`.\n",
    "\n",
    "The line `[value[0] for value in target_data.values]` does solves multiple problems.\n",
    "We cannot just pass in `target_data.values` because it's a two-dimensional array. We need to convert it into a one-dimensional array. Why? Because the world is unfair. So you take the first item of every row and add it to a list (that's the reason for the `for` loop and the `[0]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train our KNN Classifier Object\n",
    "model.fit(train_data.values, [value[0] for value in target_data.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the test file\n",
    "test_dataframe = pd.read_csv(TITANIC_TEST)\n",
    "\n",
    "# Save PassengerIds for Kaggle Submission\n",
    "ids = test_dataframe.PassengerId.values\n",
    "\n",
    "# Drop the columns we don't need\n",
    "test_dataframe.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=ROWS, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 7 columns):\n",
      "Pclass      418 non-null int64\n",
      "Sex         418 non-null object\n",
      "Age         332 non-null float64\n",
      "SibSp       418 non-null int64\n",
      "Parch       418 non-null int64\n",
      "Fare        417 non-null float64\n",
      "Embarked    418 non-null object\n",
      "dtypes: float64(2), int64(3), object(2)\n",
      "memory usage: 22.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check if our table is clean\n",
    "print(len(test_dataframe))\n",
    "test_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exact same thing we did with our training data\n",
    "mean_age = test_dataframe.Age.mean()\n",
    "test_dataframe.Age.fillna(mean_age, inplace=True)\n",
    "\n",
    "fare_mean = test_dataframe.Fare.mean()\n",
    "test_dataframe.Fare.fillna(fare_mean, inplace=True)\n",
    "\n",
    "test_dataframe['Embarked'] = test_dataframe['Embarked'].map({'C':1, 'S':2, 'Q':3, None: 0}).astype(int)\n",
    "test_dataframe['Sex'] = test_dataframe['Sex'].map({'male':0, 'female':1}).astype(int)\n",
    "\n",
    "\n",
    "test_data = test_dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 7 columns):\n",
      "Pclass      418 non-null int64\n",
      "Sex         418 non-null int64\n",
      "Age         418 non-null float64\n",
      "SibSp       418 non-null int64\n",
      "Parch       418 non-null int64\n",
      "Fare        418 non-null float64\n",
      "Embarked    418 non-null int64\n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 22.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Checking output is correct\n",
    "test_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[892   0]\n",
      " [893   0]\n",
      " [894   0]\n",
      " [895   1]\n",
      " [896   0]]\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(test_data).astype(int)\n",
    "\n",
    "result = numpy.c_[ids.astype(int), output]\n",
    "print(result[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_file = open(\"veryoriginalcode.csv\", \"w\")\n",
    "open_file_object = csv.writer(predictions_file)\n",
    "open_file_object.writerow([\"PassengerId\",\"Survived\"])\n",
    "open_file_object.writerows(zip(ids, output))\n",
    "predictions_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciKit Learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
